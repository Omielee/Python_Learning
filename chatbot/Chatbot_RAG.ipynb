{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacabbc8-3d10-4ce2-a1df-c5f8d3f615f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries using pip\n",
    "# pip install -qU\n",
    "# pip install langchain==0.0.292\n",
    "# pip install openai==0.28.0\n",
    "# pip install datasets=2.10.1\n",
    "# pip install pinecone-client==2.2.4\n",
    "# pip install tiktoken==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24dc3e9-26f5-477b-b2d5-70af1c012967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chatbot without any retrieval augmentation.\n",
    "# 放到github上时，把api删掉\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c58f44d-6734-4514-9282-83dfa0e4729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84795d8f-3ac7-4f3b-bd16-a816b2eb35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"String theory is a theoretical framework in physics that attempts to explain the fundamental nature of space, time, and matter at the most fundamental level. It suggests that instead of point-like particles, the fundamental building blocks of the universe are tiny, vibrating strings.\\n\\nHere are some key points to understand about string theory:\\n\\n1. Vibrating strings: In string theory, particles are not considered as point-like objects but rather as tiny, one-dimensional strings that vibrate in different modes. The different vibrational patterns of the strings give rise to different particles with different masses and properties.\\n\\n2. Extra dimensions: String theory proposes that the universe contains more than the three spatial dimensions (length, width, and height) that we are familiar with. It suggests the existence of additional compactified dimensions that are curled up and hidden at extremely small scales.\\n\\n3. Unifying forces: One of the main motivations behind string theory is its potential to unify the four fundamental forces of nature: gravity, electromagnetism, and the strong and weak nuclear forces. By incorporating gravity into the framework, string theory aims to provide a consistent description of all interactions in the universe.\\n\\n4. Dualities: String theory exhibits various dualities, which are mathematical equivalences between seemingly different versions of the theory. These dualities suggest that different formulations of string theory are actually different descriptions of the same underlying physics.\\n\\n5. Challenges: While string theory shows promise, it is still a work in progress. There are many challenges, including the difficulty of experimental verification due to the extremely high energy scales involved. Additionally, there are multiple versions of string theory, and finding a unique formulation that describes our universe is still an active area of research.\\n\\nIt's important to note that string theory is a highly mathematical and complex subject, and understanding it in depth requires a solid background in physics and mathematics. This overview provides a glimpse into the basic concepts, but there is much more to explore if you're interested in delving deeper into the subject.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d756ad3-e259-4880-8a5a-7cc90cf7f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a theoretical framework in physics that attempts to explain the fundamental nature of space, time, and matter at the most fundamental level. It suggests that instead of point-like particles, the fundamental building blocks of the universe are tiny, vibrating strings.\n",
      "\n",
      "Here are some key points to understand about string theory:\n",
      "\n",
      "1. Vibrating strings: In string theory, particles are not considered as point-like objects but rather as tiny, one-dimensional strings that vibrate in different modes. The different vibrational patterns of the strings give rise to different particles with different masses and properties.\n",
      "\n",
      "2. Extra dimensions: String theory proposes that the universe contains more than the three spatial dimensions (length, width, and height) that we are familiar with. It suggests the existence of additional compactified dimensions that are curled up and hidden at extremely small scales.\n",
      "\n",
      "3. Unifying forces: One of the main motivations behind string theory is its potential to unify the four fundamental forces of nature: gravity, electromagnetism, and the strong and weak nuclear forces. By incorporating gravity into the framework, string theory aims to provide a consistent description of all interactions in the universe.\n",
      "\n",
      "4. Dualities: String theory exhibits various dualities, which are mathematical equivalences between seemingly different versions of the theory. These dualities suggest that different formulations of string theory are actually different descriptions of the same underlying physics.\n",
      "\n",
      "5. Challenges: While string theory shows promise, it is still a work in progress. There are many challenges, including the difficulty of experimental verification due to the extremely high energy scales involved. Additionally, there are multiple versions of string theory, and finding a unique formulation that describes our universe is still an active area of research.\n",
      "\n",
      "It's important to note that string theory is a highly mathematical and complex subject, and understanding it in depth requires a solid background in physics and mathematics. This overview provides a glimpse into the basic concepts, but there is much more to explore if you're interested in delving deeper into the subject.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647add54-e3a8-4f81-a501-200e049d5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory because it incorporates gravity, which is not successfully described by other fundamental theories like quantum mechanics. Here are some reasons why string theory is considered a candidate for a unified theory:\n",
      "\n",
      "1. Gravity and quantum mechanics: One of the key challenges in theoretical physics is reconciling the theory of gravity (general relativity) with the theory of quantum mechanics. String theory naturally includes gravity within its framework, allowing for a consistent description of both quantum mechanics and gravity.\n",
      "\n",
      "2. Consistency and mathematical elegance: String theory offers a mathematically consistent framework for describing the fundamental forces and particles of the universe. It provides a way to explain the properties of particles and their interactions in a unified manner.\n",
      "\n",
      "3. Unification of forces: String theory suggests that all fundamental forces, including gravity, can be described by the vibrational modes of the strings. This potentially allows for a unified understanding of all known fundamental interactions.\n",
      "\n",
      "4. Dualities and equivalences: String theory exhibits various dualities, which suggest that seemingly different versions of the theory are actually different perspectives of the same underlying physics. These dualities imply a deep interconnectedness among different physical phenomena and provide evidence for the potential unification of different aspects of physics.\n",
      "\n",
      "5. Predictive power: While still a work in progress, string theory has made several predictions and calculations that match with known physics, such as reproducing the properties of certain particles and the behavior of black holes.\n",
      "\n",
      "Despite these reasons, it's important to note that string theory is an ongoing area of research and is not yet a fully developed and tested theory. Experimental verification of string theory's predictions is currently challenging due to the extremely high energy scales involved. Nevertheless, physicists continue to explore and develop the theory to find a more complete and unified understanding of the fundamental nature of the universe.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16997e23-cdbb-460d-aed3-baa0a62bf145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is so special about Llama 2?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e4a670-d7de-4147-b483-f2a3e1a9e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I am not familiar with a specific reference to \"Llama 2.\" It is possible that you may be referring to something specific or using a term that I am not aware of. Could you please provide more context or clarify your question so that I can better assist you?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b8f3ae-e03c-4814-b4e3-69b700d43239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I couldn't find any specific information about \"LLMChain\" in the context of \"LangChain.\" It is possible that these terms are related to a specific project or technology that I am not familiar with. Without more information, it is challenging for me to provide accurate details.\n",
      "\n",
      "If you could provide additional context or clarify your question, I'll do my best to assist you further.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Can you tell me about the LLMChain in LangChain?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3179d34c-6c50-4958-adb9-30bb672055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain_information = [\n",
    "    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n",
    "    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n",
    "    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(llmchain_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38f51287-e1b1-4685-b71f-3858ea080c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "Contexts:\n",
      "A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\n",
      "Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\n",
      "LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\n",
      "\n",
      "Query: Can you tell me about the LLMChain in LangChain?\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you tell me about the LLMChain in LangChain?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\"\n",
    "\n",
    "print(augmented_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9447ace6-f8d0-49c5-8144-886e7ee5946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc03d81-12af-4adc-874b-d8734a3b5915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLMChain is a specific type of chain within the LangChain framework. Chains in LangChain are comprised of modular components combined in a specific way to achieve a common objective. The LLMChain, being the most common type of chain, consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n",
      "\n",
      "The purpose of the LLMChain is to take multiple input variables, format them using the PromptTemplate into a prompt, and then pass that prompt to the language model (LLM or ChatModel). The model generates an output based on the prompt, and if provided, the OutputParser can be used to parse and format the output into the desired final format.\n",
      "\n",
      "The LangChain framework itself is designed to facilitate the development of applications powered by language models. It emphasizes the idea that powerful and differentiated applications should not only make use of language models via APIs but also be data-aware, connecting the language model to other sources of data, and be agentic, allowing the language model to interact with its environment. The LangChain framework aims to enable these types of applications by providing the necessary tools and structure.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ad60c7-37e8-4751-b088-87c1c0dba763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alpha/anaconda3/envs/chatbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n",
       "    num_rows: 4838\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"jamescalam/llama-2-arxiv-papers\",\n",
    "#                       split = \"train\")\n",
    "\n",
    "# dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\",\n",
    "                      split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c84052d-b93a-4f40-93db-501ed743ac74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '1102.0183',\n",
       " 'chunk-id': '0',\n",
       " 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n",
       " 'id': '1102.0183',\n",
       " 'title': 'High-Performance Neural Networks for Visual Object Classification',\n",
       " 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n",
       " 'source': 'http://arxiv.org/pdf/1102.0183',\n",
       " 'authors': ['Dan C. Cireşan',\n",
       "  'Ueli Meier',\n",
       "  'Jonathan Masci',\n",
       "  'Luca M. Gambardella',\n",
       "  'Jürgen Schmidhuber'],\n",
       " 'categories': ['cs.AI', 'cs.NE'],\n",
       " 'comment': '12 pages, 2 figures, 5 tables',\n",
       " 'journal_ref': None,\n",
       " 'primary_category': 'cs.AI',\n",
       " 'published': '20110201',\n",
       " 'updated': '20110201',\n",
       " 'references': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c0d136-6e39-4ca7-a6a4-87ffcf1891bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# get API key from app.pinecone.io and environment from console\n",
    "pinecone.init(\n",
    "    api_key='a7a7ab4b-27bb-40c9-bfd8-238271e60b0c',\n",
    "    environment='gcp-starter'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac422a10-78c0-4d93-be64-a3824005e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac028f7-ffe6-477c-acfa-593a30230f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.04838,\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0866dc22-880b-43ad-a686-7fc169dc3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3b4c08-f0c6-431b-b93b-6ebba539195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84952dc8-fcc7-44aa-b10d-0669d42e2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [02:04<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "         'source': x['source'],\n",
    "         'title': x['title']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3145b825-24c1-4745-983c-def74aa24455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.04838,\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd5d0397-779e-43bd-a437-c4b8c8813398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alpha/anaconda3/envs/chatbot/lib/python3.9/site-packages/langchain/vectorstores/pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5eb86c9-6689-4fbf-aa9c-4cd616abfec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom\\x03\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n",
       " Document(page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n",
       " Document(page_content='Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"What is so special about Llama 2?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0005fe94-336b-4edb-8871-457eeef7f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c51be27b-2968-46f8-956e-e13e71d41fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom\u0003\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety\n",
      "asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\n",
      "preferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\n",
      "computeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\n",
      "the community to advance AI alignment research.\n",
      "In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\n",
      "L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\n",
      "L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\n",
      "be on par with some of the closed-source models, at least on the human evaluations we performed (see\n",
      "Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\n",
      "Grave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\n",
      "arXiv:2302.13971 , 2023.\n",
      "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\n",
      "and Illia Polosukhin. Attention is all you need, 2017.\n",
      "Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\n",
      "David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\n",
      "multi-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\n",
      "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\n",
      "\n",
      "    Query: What is so special about Llama 2?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcab2062-f65f-45ee-9a0d-6410b91e7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. These LLMs, such as L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc, are specifically optimized for dialogue use cases. The special aspect of Llama 2 is that these models outperform open-source chat models on several benchmarks tested. Additionally, based on humane evaluations for helpfulness and safety, Llama 2 models may serve as suitable substitutes for closed-source models. The authors of Llama 2 provide a detailed description of their approach to fine-tuning and safety, aiming to enhance usability and safety without requiring significant costs in compute and human annotation. This transparency and reproducibility of Llama 2's approach contribute to advancing AI alignment research within the community.\n"
     ]
    }
   ],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cee1abf7-dbc6-4d0e-bc75-22959d05adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the provided context, the safety measures used in the development of Llama 2 are briefly mentioned but not explicitly described. The text mentions that the safety of the fine-tuned LLMs (Large Language Models) was considered in their development. However, the specific safety measures employed are not detailed in the given information. For a more comprehensive understanding of the safety measures implemented in Llama 2, it would be necessary to refer to the original research paper or additional sources that provide further insights into the development process and safety considerations of Llama 2.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"what safety measures were used in the development of llama 2?\"\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e995259-2c35-4ff1-9a0e-b132b46ccf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the development of Llama 2, several safety measures were employed to enhance the safety of the models. These measures include safety-specific data annotation and tuning, red-teaming, and iterative evaluations. \n",
      "\n",
      "The safety-specific data annotation and tuning involved carefully curating and annotating the data used to train the models, ensuring that potentially harmful or biased content is minimized. This process aims to improve the safety and ethical considerations of the models.\n",
      "\n",
      "Red-teaming refers to the practice of conducting adversarial testing and evaluation to identify potential vulnerabilities or risks in the models. This helps to assess and address any potential safety issues that may arise.\n",
      "\n",
      "Iterative evaluations were also carried out to continually assess the safety and performance of the models throughout the development process. This involved gathering feedback and conducting assessments from human evaluators to ensure that the models meet safety standards and perform appropriately in various scenarios.\n",
      "\n",
      "By implementing these safety measures, the developers of Llama 2 aimed to enhance the safety and responsibility of the models, enabling the community to reproduce and improve upon them while advancing the development of large language models in a more responsible manner.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(\n",
    "        \"what safety measures were used in the development of llama 2?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980786a0-c0c4-4f7a-ac3d-eb6b5dc4667d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
